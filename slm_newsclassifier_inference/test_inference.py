#!/usr/bin/env python3
"""
News Classifier Inference Test Script
ì´ì „ infer.pyì²˜ëŸ¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import requests
import json
import time

def test_inference_api():
    """APIë¥¼ í†µí•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    base_url = "http://localhost:8000"
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_texts = [
        "ì—”ì”¨ì†Œí”„íŠ¸, MMORPG 'ë¸”ë ˆì´ë“œì•¤ì†Œìš¸2' ê¸€ë¡œë²Œ ì¶œì‹œ",
        "ë„¥ìŠ¨, 2ë¶„ê¸° ì—­ëŒ€ ìµœëŒ€ ì‹¤ì  ê¸°ë¡",
        "ê²Œì„ ì‚°ì—…ì— ëŒ€í•œ ì •ë¶€ ê·œì œ ì™„í™” ë…¼ì˜",
        "ì• í”Œ, ìƒˆë¡œìš´ ì•„ì´í° ì¶œì‹œ ë£¨ë¨¸",
        "í•´ì™¸ íˆ¬ìì, í•œêµ­ ì¦ì‹œì— ê´€ì‹¬ ë‚®ì•„ì ¸",
        "ê°•ì•„ì§€ê°€ ì‚°ì±…í•˜ë‹¤ê°€ ê·€ì—¬ì›€ì„ ë°›ìŒ",
        "ë¹„ê°€ ì˜¤ëŠ” ë‚ ì”¨ì— ìš°ì‚° íŒë§¤ëŸ‰ ì¦ê°€",
        "ì¹´íŠ¸ë¼ì´ë”ì˜ ìƒˆë¡œìš´ ë§µ \"ì•„ì´ìŠ¤ì›”ë“œ\" ì¶œì‹œ",
        "ë¦¬ë‹ˆì§€ ìƒˆë¡œìš´ ìºë¦­í„° \"ì´ì¦ˆì›\" ê³µê°œ",
        "í…ì„¼íŠ¸, ë„¥ìŠ¨ ì¸ìˆ˜ ì†Œì‹",
        "ìœ„ë¯¹ìŠ¤ ìƒì¥íì§€ ì†Œì‹ì— ì£¼ê°€ ê¸‰ë½",
        "ì§€ë°°êµ¬ì¡° ì¬í¸ìœ¼ë¡œ esg íˆ¬ì ì¦ê°€",
        "ì˜¤í”ˆì›”ë“œ, \"ì•„ì¼€ì´ë“œ\"ë§µ ì „ì²´ ì—…ë°ì´íŠ¸",
        "ê°œë°œì \"íŒŒì´ë„ íŒíƒ€ì§€16\" ì¶œì‹œ ì˜ˆì •ì— ë²•ì  ëŒ€ì‘",
        "ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ ìµœì´ˆ ë°œê°„",
        "ë†í˜‘ì€í–‰ê³¼ mou ì²´ê²°í•˜ì—¬ ì±„ë¬´ ì¡°ì • ì†Œì‹",
        "ì—”ì”¨ì†Œí”„íŠ¸ ë“± ê²Œì„ì£¼ 'ì¥ì¤‘ ê¸‰ë“±'...3ëŒ€ ì´ìŠˆëŠ”?",
        "pubg: ë°°í‹€ê·¸ë¼ìš´ë“œ, êµ­ê°€ëŒ€í•­ì „ 'pnc 2025' ì„œìš¸ì—ì„œ ê°œìµœ",
        "ì•„ì´ëŒ ì½œë¼ë³´ ëŠ¦ì¶”ì â€¦ í¬ë˜í”„í†¤, 2ë¶„ê¸° ì‹¤ì  ì£¼ì¶¤",
        "í¬ë˜í”„í†¤, ë°°í‹€ê·¸ë¼ìš´ë“œ êµ­ê°€ëŒ€í•­ì „ 'pnc 2025' ê°œìµœ"
    ]
    
    print("=" * 80)
    print("ğŸ§ª News Classifier Inference API Test")
    print("=" * 80)
    
    # ì„œë²„ ìƒíƒœ í™•ì¸
    try:
        response = requests.get(f"{base_url}/", timeout=5)
        if response.status_code == 200:
            print("âœ… Server is running!")
            server_info = response.json()
            print(f"   Service: {server_info.get('service', 'N/A')}")
            print(f"   Status: {server_info.get('status', 'N/A')}")
            print(f"   Version: {server_info.get('version', 'N/A')}")
        else:
            print("âŒ Server check failed")
            return
    except requests.exceptions.RequestException:
        print("âŒ Server is not running!")
        print("   Please start the inference service first:")
        print("   cd slm-newsclassifier-inference && python main.py")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ“Š Testing Individual Predictions")
    print("=" * 80)
    
    # ê°œë³„ í…ŒìŠ¤íŠ¸
    success_count = 0
    total_count = len(test_texts)
    
    for i, text in enumerate(test_texts, 1):
        try:
            print(f"\n[{i:2d}/{total_count}] Testing: {text[:50]}{'...' if len(text) > 50 else ''}")
            
            # API í˜¸ì¶œ
            payload = {"text": text}
            response = requests.post(
                f"{base_url}/api/v1/predict",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                pred_result = result['result']
                print(f"         ğŸ¯ Label: {pred_result['label']} | Confidence: {pred_result['confidence']:.4f}")
                success_count += 1
            else:
                print(f"         âŒ Error: {response.status_code} - {response.text}")
                
        except requests.exceptions.Timeout:
            print(f"         â° Timeout error")
        except requests.exceptions.RequestException as e:
            print(f"         âŒ Request error: {e}")
        except Exception as e:
            print(f"         âŒ Unexpected error: {e}")
    
    # ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 80)
    print("ğŸ“Š Testing Batch Prediction")
    print("=" * 80)
    
    try:
        print(f"ğŸ”„ Processing {len(test_texts)} texts in batch...")
        
        payload = {"text": test_texts}
        response = requests.post(
            f"{base_url}/api/v1/predict",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            batch_results = result['result']
            print(f"âœ… Batch prediction successful! Processed {len(batch_results)} texts")
            
            # ê²°ê³¼ ìš”ì•½
            label_counts = {}
            for pred_result in batch_results:
                label = pred_result['label']
                label_counts[label] = label_counts.get(label, 0) + 1
            
            print("\nğŸ“ˆ Label Distribution:")
            for label, count in sorted(label_counts.items()):
                print(f"   Label {label}: {count} texts ({count/len(batch_results)*100:.1f}%)")
                
        else:
            print(f"âŒ Batch prediction failed: {response.status_code} - {response.text}")
            
    except requests.exceptions.Timeout:
        print("â° Batch prediction timeout")
    except Exception as e:
        print(f"âŒ Batch prediction error: {e}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“‹ Test Summary")
    print("=" * 80)
    print(f"Total tests: {total_count}")
    print(f"Successful: {success_count}")
    print(f"Failed: {total_count - success_count}")
    print(f"Success rate: {success_count/total_count*100:.1f}%")
    
    if success_count == total_count:
        print("ğŸ‰ All tests passed!")
    else:
        print("âš ï¸  Some tests failed. Please check the logs above.")

if __name__ == "__main__":
    test_inference_api() 