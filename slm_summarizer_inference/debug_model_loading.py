#!/usr/bin/env python3
"""
ëª¨ë¸ ë¡œë”© ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys

print("=== ëª¨ë¸ ë¡œë”© ë””ë²„ê¹… ì‹œì‘ ===")

# 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
print("ğŸ“‹ í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
print(f"  HUGGINGFACE_HUB_TOKEN: {repr(os.getenv('HUGGINGFACE_HUB_TOKEN'))}")
print(f"  HUGGINGFACE_TOKEN: {repr(os.getenv('HUGGINGFACE_TOKEN'))}")

# 2. ê²½ë¡œ í™•ì¸
print("\nğŸ“ ê²½ë¡œ í™•ì¸:")
print(f"  í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
print(f"  /app/slm_summarizer_training/outputs ì¡´ì¬: {os.path.exists('/app/slm_summarizer_training/outputs')}")
print(f"  ./outputs ì¡´ì¬: {os.path.exists('./outputs')}")

# 3. GPU í™•ì¸
print("\nğŸ® GPU í™•ì¸:")
try:
    import torch
    print(f"  CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"  GPU ì¥ì¹˜: {torch.cuda.get_device_name(0)}")
except Exception as e:
    print(f"  GPU í™•ì¸ ì‹¤íŒ¨: {e}")

# 4. í† í¬ë‚˜ì´ì € ë¡œë”© í…ŒìŠ¤íŠ¸
print("\nğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë”© í…ŒìŠ¤íŠ¸:")
try:
    from transformers import AutoTokenizer
    
    # í™˜ê²½ë³€ìˆ˜ ì—†ì´ í…ŒìŠ¤íŠ¸
    print("  1) í™˜ê²½ë³€ìˆ˜ ì—†ì´ í…ŒìŠ¤íŠ¸...")
    tokenizer1 = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')
    print("    âœ… ì„±ê³µ (í™˜ê²½ë³€ìˆ˜ ì—†ìŒ)")
except Exception as e:
    print(f"    âŒ ì‹¤íŒ¨ (í™˜ê²½ë³€ìˆ˜ ì—†ìŒ): {e}")

try:
    # í™˜ê²½ë³€ìˆ˜ í¬í•¨ í…ŒìŠ¤íŠ¸
    print("  2) HUGGINGFACE_HUB_TOKEN ì‚¬ìš©...")
    token = os.getenv('HUGGINGFACE_HUB_TOKEN')
    tokenizer2 = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', token=token)
    print("    âœ… ì„±ê³µ (HUGGINGFACE_HUB_TOKEN)")
except Exception as e:
    print(f"    âŒ ì‹¤íŒ¨ (HUGGINGFACE_HUB_TOKEN): {e}")

# 5. ì‹¤ì œ predictor í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
print("\nğŸ¤– Predictor í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸:")
try:
    sys.path.append('/app')
    from utils.predictor import SummarizerPredictor
    
    print("  Predictor í´ë˜ìŠ¤ ìƒì„± ì¤‘...")
    predictor = SummarizerPredictor()
    print("    âœ… Predictor ìƒì„± ì„±ê³µ")
    
    print("  ëª¨ë¸ ë¡œë”© ì‹œë„ ì¤‘...")
    import asyncio
    asyncio.run(predictor.load_model())
    print("    âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ")
    
except Exception as e:
    print(f"    âŒ Predictor í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()

print("\n=== ë””ë²„ê¹… ì™„ë£Œ ===") 