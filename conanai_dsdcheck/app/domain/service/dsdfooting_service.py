import pandas as pd
from typing import List, Dict, Any, Tuple
from app.domain.model.dsdfooting_schema import FootingResultItem, FootingResponse, YearlyFootingSheetResult
from app.domain.model.validation_rules import VALIDATION_RULES
import logging
from io import BytesIO

# ë¡œê¹… ì„¤ì • - INFO ë ˆë²¨ë¡œ ì¡°ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')

class DSDFootingService:
    """ì¬ë¬´ì œí‘œ í•©ê³„ê²€ì¦ ì„œë¹„ìŠ¤"""
    
    # D210000 ì—°ê²°ì¬ë¬´ìƒíƒœí‘œë§Œ ì²˜ë¦¬
    SHEET_TITLES = {
        "D210000": "ì—°ê²°ì¬ë¬´ìƒíƒœí‘œ"
    }

    def _preprocess_dataframe(self, sheet_name: str, xls: pd.ExcelFile) -> Dict[str, pd.DataFrame]:
        """
        ì—‘ì…€ ì‹œíŠ¸ë¥¼ ì—°ë„ë³„ DataFrameìœ¼ë¡œ ì½ê³  ì „ì²˜ë¦¬ (ë“¤ì—¬ì“°ê¸° ê¸°ë°˜ ê³„ì¸µ êµ¬ì¡° í¬í•¨)
        
        Args:
            sheet_name (str): ì‹œíŠ¸ëª…
            xls (pd.ExcelFile): ì—‘ì…€ íŒŒì¼ ê°ì²´
            
        Returns:
            Dict[str, pd.DataFrame]: ì—°ë„ë³„ë¡œ ì „ì²˜ë¦¬ëœ DataFrame
                - key: "YYYY-12-31" í˜•íƒœì˜ ì—°ë„ ë¬¸ìì—´
                - value: DataFrame (í•­ëª©ëª…, ê²½ë¡œ, ê¸ˆì•¡ ì»¬ëŸ¼ í¬í•¨)
            
        Raises:
            ValueError: ìœ íš¨í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        try:
            # í—¤ë” ì—†ì´ ë°ì´í„° ì½ê¸°
            df = pd.read_excel(xls, sheet_name, header=None)
            
            if len(df.columns) < 4:  # A, B, C, Dì—´ ìµœì†Œ í•„ìš”
                raise ValueError("Sheet must have at least 4 columns (A, B, C, D)")
            
            # 5í–‰(ì¸ë±ìŠ¤ 4)ì—ì„œ ì—°ë„ ì •ë³´ ì¶”ì¶œ (2024-12-31, 2023-12-31, 2022-12-31)
            year_row = df.iloc[4]  # 5í–‰ (0-based index)
            
            # ì—°ë„ ë§¤í•‘ ìƒì„±
            year_mapping = {}
            for col_idx in range(1, 4):  # B, C, Dì—´ (ì¸ë±ìŠ¤ 1, 2, 3)
                if col_idx < len(year_row):
                    year_str = str(year_row.iloc[col_idx]).strip()
                    if year_str and year_str != 'nan':
                        year_mapping[col_idx] = year_str
                        logging.info(f"Column {chr(65+col_idx)} -> Year: {year_str}")
            
            if not year_mapping:
                # ê¸°ë³¸ ì—°ë„ ë§¤í•‘ ì‚¬ìš©
                year_mapping = {
                    1: "2024-12-31",  # Bì—´
                    2: "2023-12-31",  # Cì—´
                    3: "2022-12-31"   # Dì—´
                }
                logging.warning("Using default year mapping")
            
            # Aì—´: í•­ëª©ëª… (6í–‰ë¶€í„° 53í–‰ê¹Œì§€, ì¸ë±ìŠ¤ 5~52)
            data_start_row = 5  # 6í–‰ (0-based index)
            data_end_row = 52   # 53í–‰ (0-based index, inclusive)
            
            # ë°ì´í„° ë²”ìœ„ ì¶”ì¶œ
            data_df = df.iloc[data_start_row:data_end_row+1].copy()
            
            # ê³„ì¸µ êµ¬ì¡° ë¶„ì„
            hierarchy = self._analyze_hierarchy(data_df)
            
            # ì—°ë„ë³„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            year_dfs = {}
            
            for col_idx, year_key in year_mapping.items():
                if col_idx >= len(data_df.columns):
                    logging.warning(f"Column index {col_idx} not found in sheet {sheet_name}")
                    continue
                
                # í•´ë‹¹ ì—°ë„ì˜ ê¸ˆì•¡ ë°ì´í„° ì¶”ì¶œ
                amount_col = data_df.iloc[:, col_idx].astype(str).str.strip()
                
                # ê¸ˆì•¡ ì „ì²˜ë¦¬
                amount_col = (amount_col
                           .str.replace(',', '', regex=False)  # ì‰¼í‘œ ì œê±°
                           .str.replace('âˆ’', '-', regex=False)  # ì „ê° ë§ˆì´ë„ˆìŠ¤ë¥¼ í•˜ì´í”ˆìœ¼ë¡œ
                           .str.replace('"', '', regex=False)   # ë”°ì˜´í‘œ ì œê±°
                           .str.replace('(', '-', regex=False)  # ê´„í˜¸ë¡œ í‘œì‹œëœ ìŒìˆ˜ ì²˜ë¦¬ ì‹œì‘
                           .str.replace(')', '', regex=False))  # ê´„í˜¸ë¡œ í‘œì‹œëœ ìŒìˆ˜ ì²˜ë¦¬ ë
                
                # ìˆ«ìë¡œ ë³€í™˜ (ë¹ˆ ë¬¸ìì—´ì´ë‚˜ 'nan'ì€ NaNìœ¼ë¡œ)
                amount_col = pd.to_numeric(amount_col, errors='coerce')
                
                # ê³„ì¸µ êµ¬ì¡° ì •ë³´ì™€ ê¸ˆì•¡ ê²°í•©
                year_data = []
                for item in hierarchy:
                    # ì›ë³¸ DataFrameì—ì„œ í•´ë‹¹ í–‰ì˜ ê¸ˆì•¡ ê°€ì ¸ì˜¤ê¸°
                    row_idx = item['row_index']  # ì›ë³¸ data_dfì—ì„œì˜ ì¸ë±ìŠ¤
                    
                    if row_idx < len(amount_col) and pd.notna(amount_col.iloc[row_idx]):
                        year_data.append({
                            'í•­ëª©ëª…': item['name'],
                            'ê²½ë¡œ': item['path'],
                            'ê¸ˆì•¡': amount_col.iloc[row_idx],
                            'ë“¤ì—¬ì“°ê¸°ë ˆë²¨': item['indent_level']
                        })
                
                # DataFrame ìƒì„±
                year_df = pd.DataFrame(year_data)
                
                if len(year_df) > 0:
                    year_dfs[year_key] = year_df
                    
                    logging.info(
                        f"ğŸ“‘ Column [{chr(65+col_idx)}] -> Year [{year_key}]: {len(year_df)} rows processed"
                    )
                    
                    # ìƒ˜í”Œ ë°ì´í„° ë¡œê¹… (ì²˜ìŒ 5ê°œ í•­ëª©)
                    sample_data = year_df.head().to_dict('records')
                    for item in sample_data:
                        logging.debug(f"  - {item['ê²½ë¡œ']}: {item['ê¸ˆì•¡']:,.0f}")
            
            if not year_dfs:
                raise ValueError("No valid year data found after preprocessing")
            
            # ì „ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
            logging.info(
                f"\nğŸ“‘ Sheet [{sheet_name}] Preprocessing Summary:\n"
                f"âœ… Total years processed: {len(year_dfs)}\n"
                f"ğŸ“… Years: {list(year_dfs.keys())}\n"
                f"ğŸ“Š Data range: Row {data_start_row+1} to {data_end_row+1}\n"
                f"ğŸ—ï¸ Hierarchy items: {len(hierarchy)}"
            )
            
            return year_dfs
            
        except Exception as e:
            logging.error(
                f"\nâš ï¸ Failed to preprocess sheet [{sheet_name}]:\n"
                f"âŒ Error: {str(e)}\n"
                f"ğŸ“Š Sheet info: {df.shape if 'df' in locals() else 'N/A'}"
            )
            raise ValueError(f"Failed to preprocess sheet {sheet_name}: {str(e)}")

    def _analyze_hierarchy(self, data_df: pd.DataFrame) -> List[Dict]:
        """
        ë“¤ì—¬ì“°ê¸° ê¸°ë°˜ ê³„ì¸µ êµ¬ì¡° ë¶„ì„
        
        Args:
            data_df (pd.DataFrame): ë°ì´í„° ë²”ìœ„ DataFrame
            
        Returns:
            List[Dict]: ê³„ì¸µ êµ¬ì¡° ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        hierarchy = []
        parent_stack = []  # ìƒìœ„ ê³„ì • ìŠ¤íƒ
        
        for i in range(len(data_df)):
            # ì›ë³¸ í•­ëª©ëª… (ë“¤ì—¬ì“°ê¸° í¬í•¨)
            original_name = str(data_df.iloc[i, 0]) if pd.notna(data_df.iloc[i, 0]) else ""
            
            # ì •ë¦¬ëœ í•­ëª©ëª…
            clean_name = original_name.strip().replace("[ê°œìš”]", "").strip()
            
            # ë¹ˆ ê°’ì´ê±°ë‚˜ "[ê°œìš”]" ì„¹ì…˜ í—¤ë”ëŠ” ê±´ë„ˆë›°ê¸°
            if not clean_name or "[ê°œìš”]" in original_name or not clean_name:
                continue
            
            # ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ ê³„ì‚° (ê³µë°± ê°œìˆ˜)
            leading_spaces = len(original_name) - len(original_name.lstrip())
            indent_level = leading_spaces // 4  # 4ì¹¸ ë‹¨ìœ„ë¡œ ë“¤ì—¬ì“°ê¸°
            
            # ìŠ¤íƒì—ì„œ í˜„ì¬ ë ˆë²¨ë³´ë‹¤ ë†’ì€ ë ˆë²¨ë“¤ ì œê±°
            while parent_stack and parent_stack[-1]['level'] >= indent_level:
                parent_stack.pop()
            
            # ê²½ë¡œ ìƒì„± (ìƒìœ„ ê³„ì • > í˜„ì¬ ê³„ì •)
            if parent_stack:
                path = ' > '.join([p['name'] for p in parent_stack] + [clean_name])
            else:
                path = clean_name
            
            # í˜„ì¬ í•­ëª©ì„ ìŠ¤íƒì— ì¶”ê°€
            parent_stack.append({
                'level': indent_level,
                'name': clean_name
            })
            
            hierarchy.append({
                'name': clean_name,
                'path': path,
                'indent_level': indent_level,
                'original': original_name,
                'row_index': i  # ë””ë²„ê¹…ìš©
            })
            
            logging.debug(f"Row {i+6}: [L{indent_level}] {path}")
        
        logging.info(f"Hierarchy analysis complete: {len(hierarchy)} items found")
        return hierarchy

    def check_footing(self, excel_file: bytes) -> FootingResponse:
        """ì—‘ì…€ íŒŒì¼ í•©ê³„ê²€ì¦ ìˆ˜í–‰"""
        try:
            # BytesIOë¡œ ì—‘ì…€ íŒŒì¼ ë˜í•‘
            with pd.ExcelFile(BytesIO(excel_file)) as xls:
                results = []
                mismatch_count = 0
                processed_sheets = 0
                
                # D210000 ì‹œíŠ¸ ì°¾ê¸°
                target_sheet = None
                for sheet_name in xls.sheet_names:
                    if "D210000" in sheet_name or sheet_name == "D210000":
                        target_sheet = sheet_name
                        break
                
                if not target_sheet:
                    raise ValueError("D210000 (ì—°ê²°ì¬ë¬´ìƒíƒœí‘œ) sheet not found in the excel file")
                
                logging.info(f"Found D210000 sheet: {target_sheet}")
                
                try:
                    # ì—°ë„ë³„ ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬
                    year_dfs = self._preprocess_dataframe(target_sheet, xls)
                    
                    # ì—°ë„ë³„ ê²€ì¦ ê²°ê³¼ ì €ì¥
                    year_results = {}
                    
                    # ê° ì—°ë„ë³„ë¡œ ê²€ì¦ ìˆ˜í–‰
                    for year, df in year_dfs.items():
                        # ê²€ì¦ ìˆ˜í–‰
                        validation_results = self._validate_sheet("D210000", df)
                        year_results[year] = validation_results
                        
                        # ë¶ˆì¼ì¹˜ í•­ëª© ì¹´ìš´íŠ¸
                        mismatch_count += sum(1 for r in validation_results if not r.is_match)
                    
                    # ì—°ë„ë³„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ ê²°ê³¼ë¡œ í†µí•©
                    sheet_result = YearlyFootingSheetResult(
                        sheet="D210000",
                        title="ì—°ê²°ì¬ë¬´ìƒíƒœí‘œ",
                        results_by_year=year_results
                    )
                    results.append(sheet_result)
                    processed_sheets += 1
                    
                except ValueError as e:
                    logging.error(f"âŒ Failed to process sheet {target_sheet}: {str(e)}")
                    raise
                except Exception as e:
                    logging.error(f"âŒ Unexpected error processing sheet {target_sheet}: {str(e)}")
                    raise
                
                if processed_sheets == 0:
                    raise ValueError("No sheets were successfully processed")
                
                if len(results) == 0:
                    raise ValueError("No validation results were generated")
                
                logging.info(f"âœ… Successfully processed {processed_sheets} sheet(s)")
                
                return FootingResponse(
                    results=results,
                    total_sheets=len(results),
                    mismatch_count=mismatch_count
                )
            
        except Exception as e:
            logging.error(f"âŒ Failed to process excel file: {str(e)}")
            raise ValueError(f"Invalid excel file format: {str(e)}")

    def _validate_sheet(self, sheet_code: str, df: pd.DataFrame) -> List[FootingResultItem]:
        """
        ê°œë³„ ì‹œíŠ¸ ê²€ì¦
        
        Args:
            sheet_code (str): ì‹œíŠ¸ ì½”ë“œ
            df (pd.DataFrame): ê²€ì¦í•  ë°ì´í„°í”„ë ˆì„
            
        Returns:
            List[FootingResultItem]: ê²€ì¦ ê²°ê³¼ ëª©ë¡
        """
        sheet_type = "ì—°ê²°ì¬ë¬´ìƒíƒœí‘œ"  # D210000ì€ í•­ìƒ ì—°ê²°ì¬ë¬´ìƒíƒœí‘œ
        
        rules = VALIDATION_RULES[sheet_type]
        results = []
        
        # í•­ëª©ëª… ë§¤ì¹­ ê²€ì‚¬
        df_items = set(df['í•­ëª©ëª…'].unique())
        rule_items = {item for item, _ in rules.items() if item != "__special_checks__"}
        
        logging.info(f"ğŸ“‹ Available items in sheet: {sorted(df_items)}")
        
        # ëˆ„ë½ëœ í•­ëª© í™•ì¸
        missing_items = rule_items - df_items
        if missing_items:
            logging.warning(
                f"\nâŒ Missing items in sheet [{sheet_code}]:\n"
                f"Expected but not found: {sorted(missing_items)}"
            )
            
            # Fuzzy matching íŒíŠ¸ ì œê³µ
            for missing in missing_items:
                # ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµ)
                normalized_missing = ''.join(c for c in missing if c.isalnum())
                matches = []
                for available in df_items:
                    normalized_available = ''.join(c for c in available if c.isalnum())
                    # ì •ê·œí™”ëœ ë¬¸ìì—´ì´ ì„œë¡œ í¬í•¨ ê´€ê³„ì¸ ê²½ìš° íŒíŠ¸ë¡œ ì¶”ê°€
                    if (normalized_missing in normalized_available or 
                        normalized_available in normalized_missing):
                        matches.append(available)
                if matches:
                    logging.info(f"ğŸ’¡ Possible matches for '{missing}': {matches}")
        
        # íŠ¹ìˆ˜ ê²€ì¦ ê·œì¹™ ì²˜ë¦¬
        if "__special_checks__" in rules:
            special_results = self._check_special_rules(df, rules["__special_checks__"])
            results.extend(special_results)
        
        # ìµœìƒìœ„ í•­ëª©ë¶€í„° ê²€ì¦ ì‹œì‘
        top_level_items = ["ìì‚°ì´ê³„", "ë¶€ì±„ì´ê³„", "ìë³¸ì´ê³„", "ìë³¸ê³¼ë¶€ì±„ì´ê³„"]
        
        for parent in top_level_items:
            if parent in rules:
                result = self._check_sum(df, parent, rules[parent], rules)
                results.append(result)
        
        return results

    def _check_special_rules(self, df: pd.DataFrame, special_rules: Dict) -> List[FootingResultItem]:
        """íŠ¹ìˆ˜ ê²€ì¦ ê·œì¹™ ì²˜ë¦¬ (ê²½ë¡œ ê¸°ë°˜)"""
        results = []
        
        for rule_name, rule in special_rules.items():
            try:
                # ì²« ë²ˆì§¸ í•­ëª© ê°’ ê°€ì ¸ì˜¤ê¸° (ê²½ë¡œ ë˜ëŠ” í•­ëª©ëª…ìœ¼ë¡œ)
                item1_rows = df[(df['ê²½ë¡œ'] == rule['í•­ëª©1']) | (df['í•­ëª©ëª…'] == rule['í•­ëª©1'])]
                if item1_rows.empty:
                    logging.warning(f"Item1 not found for special rule {rule_name}: {rule['í•­ëª©1']}")
                    continue
                item1_value = float(item1_rows['ê¸ˆì•¡'].sum())
                
                # ë‘ ë²ˆì§¸ í•­ëª©(ë“¤) ê°’ ê³„ì‚°
                item2_sum = 0
                child_results = []
                
                for item2 in rule['í•­ëª©2']:
                    item2_rows = df[(df['ê²½ë¡œ'] == item2) | (df['í•­ëª©ëª…'] == item2)]
                    if item2_rows.empty:
                        logging.warning(f"Item2 not found for special rule {rule_name}: {item2}")
                        continue
                    item2_value = float(item2_rows['ê¸ˆì•¡'].sum())
                    item2_sum += item2_value
                    
                    # í‘œì‹œìš© í•­ëª©ëª… (ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ì¶œ)
                    display_name = item2.split(' > ')[-1] if ' > ' in item2 else item2
                    
                    child_results.append(FootingResultItem(
                        item=display_name,
                        expected=None,
                        actual=item2_value,
                        is_match=True,
                        children=[]
                    ))
                
                # ê°’ ë¹„êµ (ë°˜ì˜¬ë¦¼ ì˜¤ì°¨ í—ˆìš©)
                is_match = abs(item1_value - item2_sum) < 0.01
                
                if not is_match:
                    logging.warning(
                        f"Special rule mismatch in {rule_name}: "
                        f"item1={item1_value:,.0f}, "
                        f"item2_sum={item2_sum:,.0f}, "
                        f"diff={item1_value-item2_sum:,.0f}"
                    )
                
                # í‘œì‹œìš© í•­ëª©ëª…ë“¤ (ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ì¶œ)
                item1_display = rule['í•­ëª©1'].split(' > ')[-1] if ' > ' in rule['í•­ëª©1'] else rule['í•­ëª©1']
                item2_displays = [item.split(' > ')[-1] if ' > ' in item else item for item in rule['í•­ëª©2']]
                
                results.append(FootingResultItem(
                    item=f"{rule_name} ({item1_display} {rule['ì—°ì‚°ì']} {'+'.join(item2_displays)})",
                    expected=item2_sum,
                    actual=item1_value,
                    is_match=is_match,
                    children=child_results
                ))
                
            except Exception as e:
                logging.error(f"Error checking special rule {rule_name}: {str(e)}")
                results.append(FootingResultItem(
                    item=rule_name,
                    is_match=False,
                    children=[]
                ))
        
        return results

    def _check_sum(self, df: pd.DataFrame, parent: str, children: List[str], rules: Dict) -> FootingResultItem:
        """í•­ëª©ë³„ í•©ê³„ ê²€ì¦ (ê²½ë¡œ ê¸°ë°˜)"""
        try:
            # ë¶€ëª¨ í•­ëª© ê°’ ì°¾ê¸° (ê²½ë¡œ ë˜ëŠ” í•­ëª©ëª…ìœ¼ë¡œ)
            parent_rows = df[(df['ê²½ë¡œ'] == parent) | (df['í•­ëª©ëª…'] == parent)]
            if parent_rows.empty:
                logging.warning(f"Parent item not found: {parent}")
                return FootingResultItem(
                    item=parent,
                    is_match=False,
                    children=[]
                )
            
            # ë¶€ëª¨ í•­ëª© ê°’ (ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš° í•©ì‚°)
            parent_value = float(parent_rows['ê¸ˆì•¡'].sum())
            
            # ìì‹ í•­ëª©ë“¤ì˜ í•© ê³„ì‚°
            child_results = []
            child_sum = 0
            
            for child in children:
                multiplier = -1 if child.startswith('-') else 1
                child_path = child.lstrip('-')
                
                try:
                    # ê²½ë¡œë¡œ ì •í™•íˆ ë§¤ì¹­
                    child_rows = df[df['ê²½ë¡œ'] == child_path]
                    if child_rows.empty:
                        # ê²½ë¡œê°€ ì—†ìœ¼ë©´ í•­ëª©ëª…ìœ¼ë¡œ ì‹œë„ (í•˜ìœ„ í˜¸í™˜ì„±)
                        child_name = child_path.split(' > ')[-1] if ' > ' in child_path else child_path
                        child_rows = df[df['í•­ëª©ëª…'] == child_name]
                        
                    if child_rows.empty:
                        logging.warning(f"Child item not found: {child_path} (parent: {parent})")
                        child_results.append(FootingResultItem(
                            item=child_path,
                            is_match=False,
                            children=[]
                        ))
                        continue
                    
                    # ìì‹ í•­ëª© ê°’ (ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš° í•©ì‚°)
                    child_value = float(child_rows['ê¸ˆì•¡'].sum()) * multiplier
                    child_sum += child_value
                    
                    # ìì‹ í•­ëª©ì´ ë¶€ëª¨ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ê²€ì¦
                    if child_path in rules and isinstance(rules[child_path], list):
                        child_result = self._check_sum(df, child_path, rules[child_path], rules)
                    else:
                        # ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ í•­ëª©ëª… ì¶”ì¶œí•˜ì—¬ í‘œì‹œ
                        display_name = child_path.split(' > ')[-1] if ' > ' in child_path else child_path
                        child_result = FootingResultItem(
                            item=display_name,
                            expected=None,
                            actual=child_value,
                            is_match=True,
                            children=[]
                        )
                        
                    child_results.append(child_result)
                    
                except (IndexError, ValueError) as e:
                    logging.error(f"Error processing child {child_path}: {str(e)}")
                    child_results.append(FootingResultItem(
                        item=child_path,
                        is_match=False,
                        children=[]
                    ))
            
            # í•©ê³„ ë¹„êµ (ë°˜ì˜¬ë¦¼ ì˜¤ì°¨ í—ˆìš©)
            is_match = abs(parent_value - child_sum) < 0.01
            
            if not is_match:
                logging.warning(
                    f"Mismatch in {parent}: "
                    f"expected={child_sum:,.0f}, "
                    f"actual={parent_value:,.0f}, "
                    f"diff={parent_value-child_sum:,.0f}"
                )
            else:
                logging.info(
                    f"âœ… Match in {parent}: "
                    f"expected={child_sum:,.0f}, "
                    f"actual={parent_value:,.0f}"
                )
            
            # í‘œì‹œìš© í•­ëª©ëª… (ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ì¶œ)
            display_name = parent.split(' > ')[-1] if ' > ' in parent else parent
            
            return FootingResultItem(
                item=display_name,
                expected=child_sum,
                actual=parent_value,
                is_match=is_match,
                children=child_results
            )
            
        except Exception as e:
            logging.error(f"Error checking sum for {parent}: {str(e)}")
            return FootingResultItem(
                item=parent,
                is_match=False,
                children=[]
            )